{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "Suppose a convolutional neural network has convolutions that cover $k\\times k$ pixels. After $L$ levels\n",
    "of convolutions, how many pixels are influenced by the color values at pixel location $(x, y)$\n",
    "in the input image.  Ignore any boundary effects. Here, the feature values at location $(u, v)$\n",
    "are “influenced by” location $(x, y)$ if a change in the R,G,B values at $(x, y)$ could potentially\n",
    "change the activations at $(u, v)$.\n",
    "\n",
    "Suppose a single $2\\times2$ max pooling operation is inserted after the 2nd convolution layer. How does\n",
    "this change the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is literally the same as it was in lecture13-16 with one small change. You only divide by 4 after the 2nd convolution layer instead of after every other convolution layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "\n",
    "For question 4 of lec 16-18 problems, please remember that for a given recall, $r$, the \"wiggles-eliminated\" precision is the maximum precision for all recall values greater than $r$. This is also dicussed in the HW 5 description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, I remembered it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\n",
    "\n",
    "In the transformer model, in what way is the position in the sentence ignored and in what way is it retained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the transformer model, the position in the sentence is retained using attention blocks. In attention blocks, the tokens are each connected to one another such that their position and orientation affects the token values.\n",
    "\n",
    "A position in the sentence is ignored in the case of masking, where the encoder intentionally blocks attention from connecting to words later in the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. \n",
    "\n",
    "Why does the ViT model only have an encoder while the original transformer has an encoder and a decoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ViT model shown in class doesn't need to generate an image, unlike a LLM which generates tokens. Instead, the ViT model classifies an image, which means that it doesn't need to decode a generated token. Instead, it uses a multilayer perceptron to interpret the information encoded by the transformer.\n",
    "\n",
    "This is weird, because technically, you can interpret the multilayer perceptron as the decoder, except it's just way simpler cuz all we want is classification instead of generation. Whatever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\n",
    "\n",
    "What is the point of the multi-headed attention?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-headed attention allows attention to be run in parallel (which is much faster than running 1 attention head with more parameters). The reason multi-headed attention works is because there are different \"things\" to pay attention to, and the transformer can just split each of those \"things\" it's own head, and then add up all of the results."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
