{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "Write a k-nearest neighbor classifier for the general case of k > 1. Given are\n",
    "• M data vectors each of length N, stored in an M × N NumPy array called P.\n",
    "• The class labels for the vectors stored in a length M array of integers called L. In\n",
    "particular, L[i] == c means the i-th vector in P is from class c.\n",
    "• A length N query vector called q.\n",
    "Solve this in following steps: (a) find the distance from q to each data vector, (b) find the\n",
    "class labels of the k smallest distances, (c) form a histogram of these labels and find the most\n",
    "common class label. To keep things simple, if there is a tie for the most commonly occuring\n",
    "class, you may output any of these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P (data vectors):\n",
      " [[ 0.32503281  0.56042878  0.56521208]\n",
      " [-1.51516333  0.46575668 -0.10277681]\n",
      " [ 0.50339889 -1.49906747  0.28052312]\n",
      " [-2.18605869  0.7299838  -0.76484322]\n",
      " [-2.1527459   0.0451252  -1.58575558]\n",
      " [-0.19327578 -1.22803545  0.03522589]\n",
      " [-1.00707187 -0.18196184  0.01974054]\n",
      " [ 0.60108362 -0.19632986  0.10206801]\n",
      " [ 0.82090131  0.69888559 -1.32087717]\n",
      " [-1.08578787 -0.49248876  1.22220264]]\n",
      "L (class labels):\n",
      " [2 2 0 2 0 1 2 1 0 0]\n",
      "q (query vector):\n",
      " [ 1.22258137 -1.29621628  1.23755377]\n",
      "Most common class label: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_knn_data(M=100, N=5, num_classes=3, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Generate M data vectors, each of length N\n",
    "    P = np.random.randn(M, N)  # Random normal distribution\n",
    "    \n",
    "    # Generate M class labels from num_classes\n",
    "    L = np.random.randint(0, num_classes, size=M)\n",
    "    \n",
    "    # Generate a query vector of length N\n",
    "    q = np.random.randn(N)\n",
    "    \n",
    "    return P, L, q\n",
    "\n",
    "# Generate the inputs to the problem\n",
    "P, L, q = generate_knn_data(M=10,N=3)\n",
    "print(\"P (data vectors):\\n\", P)\n",
    "print(\"L (class labels):\\n\", L)\n",
    "print(\"q (query vector):\\n\", q)\n",
    "\n",
    "k=5\n",
    "\n",
    "# Calculate the distance of every point in P to q\n",
    "distances = np.sqrt(np.sum((P - q) ** 2, axis=1))\n",
    "\n",
    "# Find the indices of the k-nearest points\n",
    "k_smallest_indices = np.argpartition(distances, k)[:k]\n",
    "\n",
    "# Convert indices to class-labels\n",
    "k_nearest_labels = L[k_smallest_indices]\n",
    "\n",
    "# Count occurrences of each class label (histogram)\n",
    "label_counts = np.bincount(k_nearest_labels)\n",
    "\n",
    "# Find the most common class label\n",
    "most_common_label = np.argmax(label_counts)\n",
    "\n",
    "print(\"Most common class label:\", most_common_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "The symmetric matching test is an alternative to the ratio test, where two keypoints, i from\n",
    "image I0 and j from I1, are said to match each other if\n",
    "• keypoint i’s descriptor is closer to the descriptor for j than any other descriptor found\n",
    "in image I0, AND\n",
    "• keypoint j’s descriptor is closer to the descriptor for i than any other descriptor found\n",
    "in image I1.\n",
    "Suppose the M0 descriptors for image I0 are stored in an M0 × k NumPy array D0 and the\n",
    "M1 descriptors for image I1 are stored in an M1 × k NumPy array D1. Write Python code to\n",
    "find all symmetric matches, outputting the idex pairs (i, j), one per line. Do this with as few\n",
    "for loops as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D0 index: 0, D1 index: 0, Distance: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def generate_random_descriptors(M0, M1, k):\n",
    "    \"\"\"\n",
    "    Generate random keypoint descriptors for two images. This isn't a part of the problem, it just generates random input\n",
    "    \n",
    "    Parameters:\n",
    "    M0 (int): Number of keypoints in image I0\n",
    "    M1 (int): Number of keypoints in image I1\n",
    "    k (int): Dimensionality of each descriptor\n",
    "    \n",
    "    Returns:\n",
    "    D0 (numpy.ndarray): M0 x k array of descriptors for image I0\n",
    "    D1 (numpy.ndarray): M1 x k array of descriptors for image I1\n",
    "    \"\"\"\n",
    "    D0 = np.random.rand(M0, k).astype(np.uint8)  # Random descriptors for image I0\n",
    "    D1 = np.random.rand(M1, k).astype(np.uint8)  # Random descriptors for image I1\n",
    "    \n",
    "    return D0, D1\n",
    "\n",
    "# Example usage\n",
    "M0, M1, k = 100, 120, 128  # Example sizes\n",
    "D0, D1 = generate_random_descriptors(M0, M1, k)\n",
    "\n",
    "# crossCheck literally does everything for us\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)  # Use L2 norm (for SIFT/SURF)\n",
    "# also, crossCheck removes one for loop (the long implementation has to use a for loop), so it's technically the \"right\" answer\n",
    "    \n",
    "matches = bf.match(D0, D1)\n",
    "\n",
    "for match in matches:\n",
    "    print(f\"D0 index: {match.queryIdx}, D1 index: {match.trainIdx}, Distance: {match.distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Is the ratio test symmetric? In other words, if keypoint i from image I0 matches keypoint j\n",
    "from image I1 by passing the ratio test, will keypoint j from image I1 match keypoint i from\n",
    "image I0 acccording to the ratio test? Justify your answer.\n",
    "\n",
    "No\n",
    "Counterexample: Suppose keypoint i from image 1 matches keypoint j from image 2. Image J may have several keypoints in image 1 that are a \"nearer.\"\n",
    "This is often in the case of images where image 1 has many keypoints and image 2 has few keypoints. Many keypoints from image 1 will all map to the same keypoint in image 2. However, the \"popular\" keypoint in image 2 won't be able to match to more than k keypoints in image 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Suppose F is the fundamental matrix mapping points (x, y) from image 0 onto “epipolar”\n",
    "lines in image 1. If (u, v) is any point in image 2, write the distance from (u, v) to the\n",
    "epiploar line as a function of u, v, z, y and F.\n",
    "\n",
    "Define $$u_1=(x,y,1)^T$$ and $$u_2=(u,v,1)^T$$\n",
    "Epipolar line: $$ax+by+c=0\\textnormal{ where }[a,b,c]=Fu_1$$\n",
    "Now use the distance formula for a line in standard form:\n",
    "$$d=\\frac{|u_2^TFu_1|}{\\sqrt{a^2+b^2}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Here is a simple implementation of a fully-connected, feed-forward network. Given are two\n",
    "Python lists, w and b, each of length L. For each i in the range 0 to L-1, w[i] holds the\n",
    "two-dimensional NumPy weight matrix for level i of the network and b[i] holds the one-dimensional (NumPy) bias vector.\n",
    "\n",
    "(a) Write code to check whether or not the dimensions of the weight arrays and bias vectors\n",
    "are consistent.\n",
    "\n",
    "(b) If x is an input vector, and sig is the activation function, write code to compute the\n",
    "output of the network. At the last layer, the activation should be the soft-max, which\n",
    "you must write yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "w = [np.random.randn(3, 2), np.random.randn(2, 3), np.random.randn(1, 2)]\n",
    "b = [np.random.randn(3), np.random.randn(2), np.random.randn(1)]\n",
    "\n",
    "def check_dimensions(w, b, input_dim):\n",
    "    prev_dim = input_dim  # Start with the input dimension\n",
    "\n",
    "    for i in range(len(w)):\n",
    "        # Check weight input matches output from the previous layer\n",
    "        if w[i].shape[1] != prev_dim:\n",
    "            return False\n",
    "\n",
    "        # Check that every weight has a bias\n",
    "        if b[i].shape[0] != w[i].shape[0]:\n",
    "            return False\n",
    "\n",
    "        prev_dim = w[i].shape[0]  # Update for the next layer\n",
    "\n",
    "    return True  # If no errors were raised, dimensions are consistent\n",
    "\n",
    "def forward_pass(x, w, b, activation=np.sigmoid):\n",
    "    \"\"\"\n",
    "    Perform a forward pass through a fully connected neural network.\n",
    "\n",
    "    Parameters:\n",
    "    - x: Input numpy array (1D)\n",
    "    - w: List of NumPy weight matrices\n",
    "    - b: List of NumPy bias vectors\n",
    "    - activation: Activation function to use (default: sigmoid)\n",
    "\n",
    "    Returns:\n",
    "    - Output of the final layer\n",
    "    \"\"\"\n",
    "    for i in range(len(w)):\n",
    "        x = np.dot(w[i], x) + b[i]  # Linear transformation\n",
    "        if i < len(w) - 1:          # Apply activation except for the last layer\n",
    "            x = activation(x)\n",
    "    x=np.softmax(x)\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
