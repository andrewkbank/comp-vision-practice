{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "Write a k-nearest neighbor classifier for the general case of k > 1. Given are\n",
    "• M data vectors each of length N, stored in an M × N NumPy array called P.\n",
    "• The class labels for the vectors stored in a length M array of integers called L. In\n",
    "particular, L[i] == c means the i-th vector in P is from class c.\n",
    "• A length N query vector called q.\n",
    "Solve this in following steps: (a) find the distance from q to each data vector, (b) find the\n",
    "class labels of the k smallest distances, (c) form a histogram of these labels and find the most\n",
    "common class label. To keep things simple, if there is a tie for the most commonly occuring\n",
    "class, you may output any of these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P (data vectors):\n",
      " [[ 0.32503281  0.56042878  0.56521208]\n",
      " [-1.51516333  0.46575668 -0.10277681]\n",
      " [ 0.50339889 -1.49906747  0.28052312]\n",
      " [-2.18605869  0.7299838  -0.76484322]\n",
      " [-2.1527459   0.0451252  -1.58575558]\n",
      " [-0.19327578 -1.22803545  0.03522589]\n",
      " [-1.00707187 -0.18196184  0.01974054]\n",
      " [ 0.60108362 -0.19632986  0.10206801]\n",
      " [ 0.82090131  0.69888559 -1.32087717]\n",
      " [-1.08578787 -0.49248876  1.22220264]]\n",
      "L (class labels):\n",
      " [2 2 0 2 0 1 2 1 0 0]\n",
      "q (query vector):\n",
      " [ 1.22258137 -1.29621628  1.23755377]\n",
      "Most common class label: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_knn_data(M=100, N=5, num_classes=3, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Generate M data vectors, each of length N\n",
    "    P = np.random.randn(M, N)  # Random normal distribution\n",
    "    \n",
    "    # Generate M class labels from num_classes\n",
    "    L = np.random.randint(0, num_classes, size=M)\n",
    "    \n",
    "    # Generate a query vector of length N\n",
    "    q = np.random.randn(N)\n",
    "    \n",
    "    return P, L, q\n",
    "\n",
    "# Generate the inputs to the problem\n",
    "P, L, q = generate_knn_data(M=10,N=3)\n",
    "print(\"P (data vectors):\\n\", P)\n",
    "print(\"L (class labels):\\n\", L)\n",
    "print(\"q (query vector):\\n\", q)\n",
    "\n",
    "k=5\n",
    "\n",
    "# Calculate the distance of every point in P to q\n",
    "distances = np.sqrt(np.sum((P - q) ** 2, axis=1))\n",
    "\n",
    "# Find the indices of the k-nearest points\n",
    "k_smallest_indices = np.argpartition(distances, k)[:k]\n",
    "\n",
    "# Convert indices to class-labels\n",
    "k_nearest_labels = L[k_smallest_indices]\n",
    "\n",
    "# Count occurrences of each class label (histogram)\n",
    "label_counts = np.bincount(k_nearest_labels)\n",
    "\n",
    "# Find the most common class label\n",
    "most_common_label = np.argmax(label_counts)\n",
    "\n",
    "print(\"Most common class label:\", most_common_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "The symmetric matching test is an alternative to the ratio test, where two keypoints, i from\n",
    "image I0 and j from I1, are said to match each other if\n",
    "• keypoint i’s descriptor is closer to the descriptor for j than any other descriptor found\n",
    "in image I0, AND\n",
    "• keypoint j’s descriptor is closer to the descriptor for i than any other descriptor found\n",
    "in image I1.\n",
    "Suppose the M0 descriptors for image I0 are stored in an M0 × k NumPy array D0 and the\n",
    "M1 descriptors for image I1 are stored in an M1 × k NumPy array D1. Write Python code to\n",
    "find all symmetric matches, outputting the idex pairs (i, j), one per line. Do this with as few\n",
    "for loops as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D0 index: 0, D1 index: 0, Distance: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def generate_random_descriptors(M0, M1, k):\n",
    "    \"\"\"\n",
    "    Generate random keypoint descriptors for two images. This isn't a part of the problem, it just generates random input\n",
    "    \n",
    "    Parameters:\n",
    "    M0 (int): Number of keypoints in image I0\n",
    "    M1 (int): Number of keypoints in image I1\n",
    "    k (int): Dimensionality of each descriptor\n",
    "    \n",
    "    Returns:\n",
    "    D0 (numpy.ndarray): M0 x k array of descriptors for image I0\n",
    "    D1 (numpy.ndarray): M1 x k array of descriptors for image I1\n",
    "    \"\"\"\n",
    "    D0 = np.random.rand(M0, k).astype(np.uint8)  # Random descriptors for image I0\n",
    "    D1 = np.random.rand(M1, k).astype(np.uint8)  # Random descriptors for image I1\n",
    "    \n",
    "    return D0, D1\n",
    "\n",
    "# Example usage\n",
    "M0, M1, k = 100, 120, 128  # Example sizes\n",
    "D0, D1 = generate_random_descriptors(M0, M1, k)\n",
    "\n",
    "# crossCheck literally does everything for us\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)  # Use L2 norm (for SIFT/SURF)\n",
    "# also, crossCheck removes one for loop (the long implementation has to use a for loop), so it's technically the \"right\" answer\n",
    "    \n",
    "matches = bf.match(D0, D1)\n",
    "\n",
    "for match in matches:\n",
    "    print(f\"D0 index: {match.queryIdx}, D1 index: {match.trainIdx}, Distance: {match.distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Is the ratio test symmetric? In other words, if keypoint i from image I0 matches keypoint j\n",
    "from image I1 by passing the ratio test, will keypoint j from image I1 match keypoint i from\n",
    "image I0 acccording to the ratio test? Justify your answer.\n",
    "\n",
    "No\n",
    "Counterexample: Suppose keypoint i from image 1 matches keypoint j from image 2. Image J may have several keypoints in image 1 that are a \"nearer.\"\n",
    "This is often in the case of images where image 1 has many keypoints and image 2 has few keypoints. Many keypoints from image 1 will all map to the same keypoint in image 2. However, the \"popular\" keypoint in image 2 won't be able to match to more than k keypoints in image 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Suppose F is the fundamental matrix mapping points (x, y) from image 0 onto “epipolar”\n",
    "lines in image 1. If (u, v) is any point in image 2, write the distance from (u, v) to the\n",
    "epiploar line as a function of u, v, z, y and F.\n",
    "\n",
    "Define $$u_1=(x,y,1)^T$$ and $$u_2=(u,v,1)^T$$\n",
    "Epipolar line: $$ax+by+c=0\\textnormal{ where }[a,b,c]=Fu_1$$\n",
    "Now use the distance formula for a line in standard form:\n",
    "$$d=\\frac{|u_2^TFu_1|}{\\sqrt{a^2+b^2}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Here is a simple implementation of a fully-connected, feed-forward network. Given are two\n",
    "Python lists, w and b, each of length L. For each i in the range 0 to L-1, w[i] holds the\n",
    "two-dimensional NumPy weight matrix for level i of the network and b[i] holds the one-dimensional (NumPy) bias vector.\n",
    "\n",
    "(a) Write code to check whether or not the dimensions of the weight arrays and bias vectors\n",
    "are consistent.\n",
    "\n",
    "(b) If x is an input vector, and sig is the activation function, write code to compute the\n",
    "output of the network. At the last layer, the activation should be the soft-max, which\n",
    "you must write yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[0.56789571 0.43210429]\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(7)\n",
    "w = [np.random.randn(3, 2), np.random.randn(2, 3), np.random.randn(2, 2)]\n",
    "b = [np.random.randn(3), np.random.randn(2), np.random.randn(2)]\n",
    "def check_dimensions(w, b, input_dim):\n",
    "    prev_dim = input_dim  # Start with the input dimension\n",
    "\n",
    "    for i in range(len(w)):\n",
    "        # Check weight input matches output from the previous layer\n",
    "        if w[i].shape[1] != prev_dim:\n",
    "            return False\n",
    "\n",
    "        # Check that every weight has a bias\n",
    "        if b[i].shape[0] != w[i].shape[0]:\n",
    "            return False\n",
    "\n",
    "        prev_dim = w[i].shape[0]  # Update for the next layer\n",
    "\n",
    "    return True  # If no errors were raised, dimensions are consistent\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "def forward_pass(x, w, b, activation=sigmoid):\n",
    "    \"\"\"\n",
    "    Perform a forward pass through a fully connected neural network.\n",
    "\n",
    "    Parameters:\n",
    "    - x: Input numpy array (1D)\n",
    "    - w: List of NumPy weight matrices\n",
    "    - b: List of NumPy bias vectors\n",
    "    - activation: Activation function to use (default: sigmoid)\n",
    "\n",
    "    Returns:\n",
    "    - Output of the final layer\n",
    "    \"\"\"\n",
    "    for i in range(len(w)):\n",
    "        x = np.dot(w[i], x) + b[i]  # Linear transformation\n",
    "        if i < len(w) - 1:          # Apply activation except for the last layer\n",
    "            x = activation(x)\n",
    "    x=softmax(x)\n",
    "    return x\n",
    "\n",
    "print(check_dimensions(w,b,2))\n",
    "x = np.random.randn(2)\n",
    "print(forward_pass(x,w,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Is k-means clustering affected by outliers — points far from any others? Explain your answer.\n",
    "Is the same true of agglomerative clustering?\n",
    "\n",
    "K-means clustering is affected by outliers. K-means uses mean to find k clusters and centroids, and mean is influenced by outliers. One of the cluster's must contain the outlier, and that outlier will greatly affect that cluster's centroid.\n",
    "Agglomerative clustering isn't affected by outliers. Agglomerative uses distances between points to determine clusters. As long as the hyperparamater (the max cluster radius) is small enough, outliers will be effectively ignored/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Draw examples of data sets that k-mean clustering does well on and does poorly on. Do the\n",
    "same for agglomerative clustering. Explain what you are showing.\n",
    "\n",
    "well:\n",
    "k-means: round clusters\n",
    "agglomerative: any shape clusters with uniform density\n",
    "\n",
    "poorly:\n",
    "k-means: anything with outliers or non-circular clusters\n",
    "agglomerative: clusters have differing densities or a really large dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Consider a non-convolutional neural network that starts from an RGB input image of size\n",
    "N × N. It has L layers with h nodes per hidden layer, and n nodes in the output layer.\n",
    "Suppose each layer is fully-connected to the previous layer and there is a separate bias term\n",
    "at each node of at each layer. Derive a formula to describe the number of learnable parameters\n",
    "in the network.\n",
    "\n",
    "Input to first hidden layer: 3 color channels for N x N pixels. Every R G and B pixel has a weight for each node of the hidden layer\n",
    "$$3N^2h$$\n",
    "Between each hidden layer: h nodes each have a weight for each node in the next hidden layer. Additionally every node in the next hidden layer has a weight for the bias.\n",
    "$$h^2+h$$\n",
    "L-2 total hidden layer transitions\n",
    "$$(L-2)(h^2+h)$$\n",
    "Final output layer: h nodes each have a weight for each node in the output layer. Additionally, every node in the output layer has a weight for the bias.\n",
    "$$nh+n$$\n",
    "In total, that's\n",
    "$$3N^2h+(L-2)(h^2+h)+nh+n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Redo the computational graph computation examples from Lecture 12.\n",
    "$$C=\\frac{1}{2}(y-a_2)^2$$\n",
    "$$a_2=\\sigma(z_2)$$\n",
    "$$z_2=w_1x_1+w_2a_1+b_2$$\n",
    "$$a_1=\\sigma(z_1)$$\n",
    "$$z_1=w_3x_3+w_4x_4$$\n",
    "\n",
    "$$\\frac{\\delta C}{\\delta z_2}=\\frac{\\delta C}{\\delta a_2}\\frac{\\delta a_2}{\\delta z_2}=(a_2-y)\\sigma'(z_2)$$\n",
    "$$\\frac{\\delta C}{\\delta w_1}=\\frac{\\delta C}{\\delta z_2}\\frac{\\delta z_2}{\\delta w_1}=(a_2-y)\\sigma'(z_2)x_1$$\n",
    "$$\\frac{\\delta C}{\\delta w_2}=\\frac{\\delta C}{\\delta z_2}\\frac{\\delta z_2}{\\delta w_2}=(a_2-y)\\sigma'(z_2)a_1$$\n",
    "$$\\frac{\\delta C}{\\delta b_2}=\\frac{\\delta C}{\\delta z_2}\\frac{\\delta z_2}{\\delta b_2}=(a_2-y)\\sigma'(z_2)$$\n",
    "$$\\frac{\\delta C}{\\delta z_1}=\\frac{\\delta C}{\\delta z_2}\\frac{\\delta z_2}{\\delta a_1}\\frac{\\delta a_1}{\\delta z_1}=(a_2-y)\\sigma'(z_2)w_2\\sigma'(z_1)$$\n",
    "$$\\frac{\\delta C}{\\delta w_3}=\\frac{\\delta C}{\\delta z_1}\\frac{\\delta z_1}{\\delta w_3}=(a_2-y)\\sigma'(z_2)w_2\\sigma'(z_1)x_3$$\n",
    "$$\\frac{\\delta C}{\\delta w_4}=\\frac{\\delta C}{\\delta z_1}\\frac{\\delta z_1}{\\delta w_4}=(a_2-y)\\sigma'(z_2)w_2\\sigma'(z_1)x_4$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Here are the equations of a simple layered computational graph\n",
    "$$C=\\frac{1}{2}(y-a^2)^2$$\n",
    "$$a^2=\\sigma(z^2)$$\n",
    "$$z^2=w^2_1a^1_1+w^2_2a^1_2$$\n",
    "$$a^1_1=\\sigma(z^1_1)$$\n",
    "$$a^1_2=\\sigma(z^1_2)$$\n",
    "$$z^1_1=w^1_{1,1}x_1+w^1_{1,2}x_2$$\n",
    "$$z^1_2=w^1_{2,1}x_1+w^1_{2,2}x_2$$\n",
    "The superscripts indicate the layers, so that for example $a^1_2$ is the second activation variable at layer 1 and $w^1_{2,1}$ is a layer 1 weight from $x_1$ to $z^1_2$.\n",
    "\n",
    "• The lone exception is the equation for C where the outermost 2 superscript is in fact “square”. Sorry for the weirdness.\n",
    "\n",
    "Complete the three derivations:\n",
    "$$\\frac{\\delta C}{\\delta z^2}=\\frac{\\delta C}{\\delta a^2}\\frac{\\delta a^2}{\\delta z^2}=(a^2-y)\\sigma'(z^2)$$\n",
    "$$\\frac{\\delta C}{\\delta z^1_1}=\\frac{\\delta C}{\\delta z^2}\\frac{\\delta z^2}{\\delta a^1_1}\\frac{\\delta a^1_1}{\\delta z^1_1}=(a^2-y)\\sigma'(z^2)2^2_1\\sigma'(z^1_1)$$\n",
    "$$\\frac{\\delta C}{\\delta w^1_{1,1}}=\\frac{\\delta C}{\\delta z^1_1}\\frac{\\delta z^1_1}{\\delta w^1_{1,1}}=(a^2-y)\\sigma'(z^2)2^2_1\\sigma'(z^1_1)x_1$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
