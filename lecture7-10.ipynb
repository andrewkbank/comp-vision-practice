{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to apply non-maximum suppression to a NumPy array called v that you should\n",
    "treat as a circle, so that that last entry in v is “next to” the 0th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0 18  0  0  0  0  8  0  0 14]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.array([8,6,7,8,11,15,18,17,8,6,4,8,5,8,14])\n",
    "\n",
    "# non-maximum suppression (we are allowed to use a for-loop here)\n",
    "def getPrev(v,index):\n",
    "    if index==0:\n",
    "        return v[len(v)-1]\n",
    "    return v[index-1]\n",
    "def getNext(v,index):\n",
    "    if(index==len(v)-1):\n",
    "        return v[0]\n",
    "    return v[index+1]\n",
    "\n",
    "v2 = np.copy(v)\n",
    "for i in range(len(v)):\n",
    "    if getPrev(v,i)>v[i] or getNext(v,i)>v[i]:\n",
    "        v2[i]=0\n",
    "v=v2\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as a second step, write additional code to eliminate any local maximum in v that is less than 70% of the maximum across the entire array (no for loops allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0 18  0  0  0  0  0  0  0 14]\n"
     ]
    }
   ],
   "source": [
    "max_val = np.max(v)\n",
    "v[v<max_val*0.7] = 0\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have an M×N image and you have detected a SIFT keypoint at location (x, y),\n",
    "orientation θ, and scale σ. Now suppose you resize the image to 2M × 2N. Where will there\n",
    "be a SIFT keypoint in the new image and what will be its orientation and scale?\n",
    "\n",
    "Answer: (2x,2y), 2σ, θ (theta remains unchanged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After SIFT keypoint detection, orientation estimation, and the calculation of the 4 × 4 grid of 8-component orientation histograms, you must convert the 16 histograms to a 128 component descriptor vector. Each of these vectors must be normalized to make them unit vectors. After normalization, any value greater than 0.3 must be truncated to 0.3. (This is an experimentally-derived heuristic.) The final step is to normalize again so the vectors are once again unit vectors.\n",
    "\n",
    "Implement these operations assuming you are starting from a 4 dimensional NumPy array called B, which has dimensions N × 4 × 4 × 8. The final descriptor vector should be stored in a N × 128 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1  # Replace with your desired value for N\n",
    "B = np.random.rand(N, 4, 4, 8)  # Random values from uniform distribution [0, 1)\n",
    "\n",
    "# Step 1: Flatten B into shape (N, 128)\n",
    "descriptors = B.reshape(N, 128)\n",
    "\n",
    "# Step 2: Normalize each descriptor to unit length (L2 normalization)\n",
    "norms = np.linalg.norm(descriptors, axis=1, keepdims=True)\n",
    "descriptors = descriptors / (norms + 1e-10)  # Adding small epsilon to prevent division by zero\n",
    "\n",
    "# Step 3: Threshold values greater than 0.3\n",
    "descriptors = np.clip(descriptors, None, 0.3)\n",
    "\n",
    "# Step 4: Normalize again to make unit vectors\n",
    "norms = np.linalg.norm(descriptors, axis=1, keepdims=True)\n",
    "descriptors = descriptors / (norms + 1e-10)\n",
    "\n",
    "#print(descriptors.shape)  # Should print (N, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True or False: If you are given two images of the same scene taken by two different cameras\n",
    "(no lens distortions), there will exist a homography H that accurately maps one image onto\n",
    "the other, and there will exist a fundamental matrix F that accurately maps points from one\n",
    "image onto lines that contain their corresponding points in the other image. Justify your\n",
    "answer.\n",
    "\n",
    "False, homography only can capture a rotating camera, not a translating camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose camera i, for i = 1, 2, is described by the intrinsic parameter matrix Ki, rotation\n",
    "matrix Ri and translation vector t = (0, 0, 0)^T. This would give camera matrix\n",
    "    Mi=(KiRi | 0)\n",
    "\n",
    "Note that in this notation we have dropped the transpose on the rotation matrix. For this\n",
    "exercise, we’ll assume all pixel locations are written in the form (x, y), where x is across the\n",
    "image and y goes down.\n",
    "\n",
    "\n",
    "Write Python code that computes the bounds of the mapping of an image from camera 1\n",
    "onto camera 2 and on the mapping of camera 2 onto camera 1. Given four 3x3 matrices, K1,\n",
    "R1, K2 and R2, the code should\n",
    "\n",
    "(a) Compute the homography mapping image 1 onto image 2,\n",
    "(b) Map the four corners of image 1 onto image 2 using this homography,\n",
    "(c) Compute the corners of the rectangle (in image 2’s coordinate system) bounding these\n",
    "points,\n",
    "(d) Output the upper left and lower right corners for this bounding rectangle, accurate to\n",
    "the nearest integer, and\n",
    "(e) Repeat steps 2 through 5, reversing the roles of camera 1 and 2\n",
    "\n",
    "You may assume the corners of the images are (0,0), (6000, 0), (0, 4000), and (6000, 4000).\n",
    "For simplicity there should just be four lines of output\n",
    "• the x and y coordinates of the upper left corner of the first mapping,\n",
    "• the x and y coordinates of the lower right corner of the first mapping,\n",
    "• the x and y coordinates of the upper left corner of the second mapping, and\n",
    "• the x and y coordinates of the lower right corner of the second mapping.\n",
    "All output values should be rounded to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71226422 1.4370184 ]\n",
      "[  1.6089314  -46.83327706]\n",
      "[0.64520982 3.37365059]\n",
      "[0.70709179 0.15100759]\n",
      "[[  0.71226424   1.4370184 ]\n",
      " [  1.6089314  -46.83328   ]\n",
      " [  0.7070918    0.1510076 ]\n",
      " [  0.64520985   3.3736506 ]]\n",
      "Upper Left corner: (0.6452098488807678, -46.83327865600586)\n",
      "Lower right corner: (1.6089314222335815, 3.373650550842285)\n",
      "[[3.0224414 3.341623 ]\n",
      " [2.8161461 3.210723 ]\n",
      " [2.8447387 3.2094004]\n",
      " [5.097248  3.1039047]]\n",
      "Upper Left corner: (2.8161461353302, 3.1039047241210938)\n",
      "Lower right corner: (5.097248077392578, 3.341623067855835)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "K1 = np.random.rand(3,3)\n",
    "K2 = np.random.rand(3,3)\n",
    "R1 = np.random.rand(3,3)\n",
    "R2 = np.random.rand(3,3)\n",
    "\n",
    "# Note that we use inv(K1) instead of transpose(K1) because the problem is weird (it does make it easier to remember though)\n",
    "# To remember this formula, just know that Mi described in the problem goes from world to pixel. Mi gives us KiRi in the problem, so to go the other way (from pixel to world), it's just inv(KiRi)\n",
    "H = K2@R2@np.linalg.inv(K1)@np.linalg.inv(R1)\n",
    "\n",
    "# Calculate corners translated from pixels in Camera 1 to pixels in Camera 2\n",
    "# Note we need to add an extra 1 in the z dimension because H is a 3x3 matrix\n",
    "corner1 = H @ np.array([0,0,1])\n",
    "corner2 = H @ np.array([6000,0,1])\n",
    "corner3 = H @ np.array([0,4000,1])\n",
    "corner4 = H @ np.array([6000,4000,1])\n",
    "\n",
    "# Note that these corner points have 3 dimensions instead of 2\n",
    "# We get rid of the z-coordinate by just dividing the x and y coordinate by the z coordinate\n",
    "corner1 = np.array([corner1[0]/corner1[2], corner1[1]/corner1[2]])\n",
    "corner2 = np.array([corner2[0]/corner2[2], corner2[1]/corner2[2]])\n",
    "corner3 = np.array([corner3[0]/corner3[2], corner3[1]/corner3[2]])\n",
    "corner4 = np.array([corner4[0]/corner4[2], corner4[1]/corner4[2]])\n",
    "\n",
    "print(corner1)\n",
    "print(corner2)\n",
    "print(corner3)\n",
    "print(corner4)\n",
    "\n",
    "\n",
    "#Alternatively, you can use cv2 to find the transformed corners (note, I copied this straight from the homework):\n",
    "corners1 = np.array([[0, 0], [6000, 0], [6000, 4000], [0, 4000]], dtype=np.float32)\n",
    "corners1_transformed = cv2.perspectiveTransform(corners1.reshape(-1, 1, 2), H).reshape(-1, 2)\n",
    "print(corners1_transformed)\n",
    "\n",
    "# Get the bounding box of the transformed image1\n",
    "min_x = corners1_transformed[:, 0].min()\n",
    "min_y = corners1_transformed[:, 1].min()\n",
    "max_x = corners1_transformed[:, 0].max()\n",
    "max_y = corners1_transformed[:, 1].max()\n",
    "\n",
    "# Note that the coordinate system is different than usual\n",
    "print(f\"Upper Left corner: ({min_x}, {min_y})\")\n",
    "print(f\"Lower right corner: ({max_x}, {max_y})\")\n",
    "\n",
    "# Now go from Camera 2 to Camera 1:\n",
    "H = np.linalg.inv(H)\n",
    "corners1 = np.array([[0, 0], [6000, 0], [6000, 4000], [0, 4000]], dtype=np.float32)\n",
    "corners1_transformed = cv2.perspectiveTransform(corners1.reshape(-1, 1, 2), H).reshape(-1, 2)\n",
    "print(corners1_transformed)\n",
    "\n",
    "# Get the bounding box of the transformed image1\n",
    "min_x = corners1_transformed[:, 0].min()\n",
    "min_y = corners1_transformed[:, 1].min()\n",
    "max_x = corners1_transformed[:, 0].max()\n",
    "max_y = corners1_transformed[:, 1].max()\n",
    "\n",
    "# Note that the coordinate system is different than usual\n",
    "print(f\"Upper Left corner: ({min_x}, {min_y})\")\n",
    "print(f\"Lower right corner: ({max_x}, {max_y})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
