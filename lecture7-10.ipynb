{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to apply non-maximum suppression to a NumPy array called v that you should\n",
    "treat as a circle, so that that last entry in v is “next to” the 0th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0 18  0  0  0  0  8  0  0 14]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v = np.array([8,6,7,8,11,15,18,17,8,6,4,8,5,8,14])\n",
    "\n",
    "# non-maximum suppression (we are allowed to use a for-loop here)\n",
    "def getPrev(v,index):\n",
    "    if index==0:\n",
    "        return v[len(v)-1]\n",
    "    return v[index-1]\n",
    "def getNext(v,index):\n",
    "    if(index==len(v)-1):\n",
    "        return v[0]\n",
    "    return v[index+1]\n",
    "\n",
    "v2 = np.copy(v)\n",
    "for i in range(len(v)):\n",
    "    if getPrev(v,i)>v[i] or getNext(v,i)>v[i]:\n",
    "        v2[i]=0\n",
    "v=v2\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as a second step, write additional code to eliminate any local maximum in v that is less than 70% of the maximum across the entire array (no for loops allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0 18  0  0  0  0  0  0  0 14]\n"
     ]
    }
   ],
   "source": [
    "max_val = np.max(v)\n",
    "v[v<max_val*0.7] = 0\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have an M×N image and you have detected a SIFT keypoint at location (x, y),\n",
    "orientation θ, and scale σ. Now suppose you resize the image to 2M × 2N. Where will there\n",
    "be a SIFT keypoint in the new image and what will be its orientation and scale?\n",
    "\n",
    "Answer: (2x,2y), 2σ, θ (theta remains unchanged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After SIFT keypoint detection, orientation estimation, and the calculation of the 4 × 4 grid of 8-component orientation histograms, you must convert the 16 histograms to a 128 component descriptor vector. Each of these vectors must be normalized to make them unit vectors. After normalization, any value greater than 0.3 must be truncated to 0.3. (This is an experimentally-derived heuristic.) The final step is to normalize again so the vectors are once again unit vectors.\n",
    "\n",
    "Implement these operations assuming you are starting from a 4 dimensional NumPy array called B, which has dimensions N × 4 × 4 × 8. The final descriptor vector should be stored in a N × 128 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128)\n"
     ]
    }
   ],
   "source": [
    "N = 1  # Replace with your desired value for N\n",
    "B = np.random.rand(N, 4, 4, 8)  # Random values from uniform distribution [0, 1)\n",
    "\n",
    "# Step 1: Flatten B into shape (N, 128)\n",
    "descriptors = B.reshape(N, 128)\n",
    "\n",
    "# Step 2: Normalize each descriptor to unit length (L2 normalization)\n",
    "norms = np.linalg.norm(descriptors, axis=1, keepdims=True)\n",
    "descriptors = descriptors / (norms + 1e-10)  # Adding small epsilon to prevent division by zero\n",
    "\n",
    "# Step 3: Threshold values greater than 0.3\n",
    "descriptors = np.clip(descriptors, None, 0.3)\n",
    "\n",
    "# Step 4: Normalize again to make unit vectors\n",
    "norms = np.linalg.norm(descriptors, axis=1, keepdims=True)\n",
    "descriptors = descriptors / (norms + 1e-10)\n",
    "\n",
    "#print(descriptors.shape)  # Should print (N, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True or False: If you are given two images of the same scene taken by two different cameras\n",
    "(no lens distortions), there will exist a homography H that accurately maps one image onto\n",
    "the other, and there will exist a fundamental matrix F that accurately maps points from one\n",
    "image onto lines that contain their corresponding points in the other image. Justify your\n",
    "answer.\n",
    "\n",
    "False, homography only can capture a rotating camera, not a translating camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose camera i, for i = 1, 2, is described by the intrinsic parameter matrix Ki, rotation\n",
    "matrix Ri and translation vector t = (0, 0, 0)^T. This would give camera matrix\n",
    "    Mi=(KiRi | 0)\n",
    "\n",
    "Note that in this notation we have dropped the transpose on the rotation matrix. For this\n",
    "exercise, we’ll assume all pixel locations are written in the form (x, y), where x is across the\n",
    "image and y goes down.\n",
    "\n",
    "\n",
    "Write Python code that computes the bounds of the mapping of an image from camera 1\n",
    "onto camera 2 and on the mapping of camera 2 onto camera 1. Given four 3x3 matrices, K1,\n",
    "R1, K2 and R2, the code should\n",
    "\n",
    "(a) Compute the homography mapping image 1 onto image 2,\n",
    "(b) Map the four corners of image 1 onto image 2 using this homography,\n",
    "(c) Compute the corners of the rectangle (in image 2’s coordinate system) bounding these\n",
    "points,\n",
    "(d) Output the upper left and lower right corners for this bounding rectangle, accurate to\n",
    "the nearest integer, and\n",
    "(e) Repeat steps 2 through 5, reversing the roles of camera 1 and 2\n",
    "\n",
    "You may assume the corners of the images are (0,0), (6000, 0), (0, 4000), and (6000, 4000).\n",
    "For simplicity there should just be four lines of output\n",
    "• the x and y coordinates of the upper left corner of the first mapping,\n",
    "• the x and y coordinates of the lower right corner of the first mapping,\n",
    "• the x and y coordinates of the upper left corner of the second mapping, and\n",
    "• the x and y coordinates of the lower right corner of the second mapping.\n",
    "All output values should be rounded to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.27139677 0.72228557 0.37163059]\n",
      " [4.3263142  0.66744523 0.30463621]\n",
      " [1.20571336 0.36721405 0.07629303]]\n",
      "[0. 0. 0.]\n",
      "[31628.38061547 25957.88517285  7234.28017152]\n",
      "[2889.14229785 2669.78091681 1468.85620833]\n",
      "[34517.52291332 28627.66608966  8703.13637985]\n",
      "[[1.08942623 1.22307049 1.39991746 0.        ]\n",
      " [0.9829921  1.07681129 1.19476974 0.        ]\n",
      " [0.41182661 0.49538443 0.44564035 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "K1 = np.random.rand(3,3)\n",
    "K2 = np.random.rand(3,3)\n",
    "R1 = np.random.rand(3,3)\n",
    "R2 = np.random.rand(3,3)\n",
    "\n",
    "# Compute the inverse of K1\n",
    "K1_inv = np.linalg.inv(K1)\n",
    "\n",
    "H = K2 @ R2 @ R1.T @ K1_inv\n",
    "print(H)\n",
    "\n",
    "corner1 = H @ np.array([0,0,0])\n",
    "corner2 = H @ np.array([6000,0,0])\n",
    "corner3 = H @ np.array([0,4000,0])\n",
    "corner4 = H @ np.array([6000,4000,0])\n",
    "\n",
    "print(corner1)\n",
    "print(corner2)\n",
    "print(corner3)\n",
    "print(corner4)\n",
    "\n",
    "# camera matrix 2\n",
    "M2 = np.hstack((K2@R2, np.zeros((3,1))))\n",
    "#print(M2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
